import os
import json
import torch
from pathlib import Path
from typing import List, Tuple, Optional
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import openai
from dotenv import load_dotenv


class GoogleAPIRAGSystem:
    """êµ¬ê¸€ API ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ RAG ì‹œìŠ¤í…œ (GPT-4o ì „ìš©)"""

    def __init__(self,
                 api_data_dir: str = "./GOOGLE_API_DATA",
                 db_dir: str = "./chroma_google_api_db_gpt",
                 openai_api_key: str = None):
        """
        Args:
            api_data_dir: êµ¬ê¸€ API ì›ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬. í•˜ìœ„ í´ë”ëª…ì„ API ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            db_dir: Chroma DB ì €ì¥ ê²½ë¡œ
            openai_api_key: OpenAI API í‚¤ (í•„ìˆ˜)
        """
        if not openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. `openai_api_key` ì¸ìë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")

        self.api_data_dir = Path(api_data_dir)
        self.db_dir = db_dir

        # OpenAI ì„¤ì •
        os.environ["OPENAI_API_KEY"] = openai_api_key
        openai.api_key = openai_api_key

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.documents: List[Document] = []
        self.vectorstore: Optional[Chroma] = None
        self.retriever = None
        self.embedding_model: Optional[HuggingFaceEmbeddings] = None
        self.llm: Optional[ChatOpenAI] = None

    def _get_category_from_path(self, file_path: Path) -> str:
        """
        íŒŒì¼ ê²½ë¡œì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì´ë¦„ìœ¼ë¡œë¶€í„° API ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        ì´ ë°©ì‹ì€ ë©”íƒ€ë°ì´í„°ë¥¼ íŒŒì¼ì˜ ë‚´ìš©ì´ ì•„ë‹Œ í´ë” êµ¬ì¡°ì— ë”°ë¼ ê³ ì •ì‹œí‚µë‹ˆë‹¤.

        ì˜ˆì‹œ:
        - ./GOOGLE_API_DATA/gmail/send_email.txt -> 'gmail'
        - ./GOOGLE_API_DATA/drive/list_files.txt -> 'drive'
        - ./GOOGLE_API_DATA/some_other_doc.txt -> 'general'
        """
        try:
            relative_path = file_path.relative_to(self.api_data_dir)
            # ìƒëŒ€ ê²½ë¡œì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ì¹´í…Œê³ ë¦¬ (í´ë”ëª…)
            if len(relative_path.parts) > 1:
                return relative_path.parts[0]
        except ValueError:
            # api_data_dir ì™¸ë¶€ì— ìˆëŠ” ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ)
            pass
        # íŒŒì¼ì´ ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ì§ì ‘ ìˆì„ ê²½ìš° 'general'ë¡œ ë¶„ë¥˜
        return 'general'

    def load_api_documents(self) -> List[Document]:
        """
        êµ¬ê¸€ API ì›ë¬¸ ë¬¸ì„œë“¤ì„ ë¡œë“œí•˜ê³  Document ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ íƒìƒ‰í•˜ë©°, ë””ë ‰í† ë¦¬ ì´ë¦„ì„ API ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        documents = []

        if not self.api_data_dir.exists():
            print(f"âš ï¸ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.api_data_dir}")
            self.documents = documents
            return documents

        print(f"ğŸ“‚ API ë°ì´í„° ë¡œë“œ ì¤‘ (í•˜ìœ„ í´ë” í¬í•¨): {self.api_data_dir}")
        file_paths = list(self.api_data_dir.rglob("*.txt")) + list(self.api_data_dir.rglob("*.json"))

        for file_path in file_paths:
            try:
                content = ""
                if file_path.suffix == '.txt':
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                elif file_path.suffix == '.json':
                    with open(file_path, 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                    content = json.dumps(json_data, ensure_ascii=False, indent=2)

                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1500, chunk_overlap=300
                )
                chunks = text_splitter.split_text(content)

                for i, chunk in enumerate(chunks):
                    # ë©”íƒ€ë°ì´í„° êµ¬ì¡°ë¥¼ í†µì¼í•˜ê³ , í´ë”ëª…ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ê³ ì •
                    doc = Document(
                        page_content=chunk,
                        metadata={
                            'source_file': str(file_path.relative_to(self.api_data_dir)),
                            'chunk_id': i,
                            'api_category': self._get_category_from_path(file_path)
                        }
                    )
                    documents.append(doc)

            except Exception as e:
                print(f"âš ï¸ {file_path} íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        self.documents = documents
        print(f"âœ… ì´ {len(documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return documents

    def initialize_vectorstore(self):
        """ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ë° ë¬¸ì„œ ì„ë² ë”©"""
        print("ğŸ”§ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘... (BAAI/bge-m3)")
        self.embedding_model = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

        if os.path.exists(self.db_dir) and any(Path(self.db_dir).iterdir()):
            print(f"ğŸ’¾ ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘: {self.db_dir}")
            self.vectorstore = Chroma(
                persist_directory=self.db_dir,
                embedding_function=self.embedding_model
            )
        else:
            if not self.documents:
                self.load_api_documents()
            if not self.documents:
                print("âš ï¸ ë²¡í„° DBë¥¼ ìƒì„±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return

            print("ğŸ’¾ ìƒˆ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...")
            self.vectorstore = Chroma.from_documents(
                documents=self.documents,
                embedding=self.embedding_model,
                persist_directory=self.db_dir,
            )

        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={"k": 5, "score_threshold": 0.3}
        )
        print(f"âœ… ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„ ì™„ë£Œ ({self.db_dir})")

    def initialize_llm(self):
        """LLM ëª¨ë¸(GPT-4o) ì´ˆê¸°í™”"""
        print("ğŸ¤– GPT-4o ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0.7, max_tokens=1024)
        print("âœ… GPT-4o ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")

    def format_docs_for_context(self, docs: List[Document]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        formatted = []
        for i, doc in enumerate(docs, 1):
            content = f"[ì°¸ê³  ìë£Œ {i}]\n"
            content += f"- ì¶œì²˜: {doc.metadata.get('source_file', 'N/A')}\n"
            content += f"- ì¹´í…Œê³ ë¦¬: {doc.metadata.get('api_category', 'N/A')}\n"
            content += f"- ë‚´ìš©: {doc.page_content}"
            formatted.append(content)
        return "\n\n---\n\n".join(formatted)

    def generate_response(self, query: str) -> Tuple[List[Document], str]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        if not self.llm or not self.retriever:
            raise RuntimeError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `initialize_all()`ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = self.retriever.invoke(query)

        # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.format_docs_for_context(docs)

        # 3. LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            SystemMessage(content="""ë‹¹ì‹ ì€ êµ¬ê¸€ API ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°œë°œìë“¤ì—ê²Œ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
            ì œê³µëœ 'ì°¸ê³  ìë£Œ'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©°, ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
            ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""),
            HumanMessage(content=f"ì°¸ê³  ìë£Œ:\n{context}\n\n---\nì§ˆë¬¸: {query}\n\nìœ„ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:")
        ]

        # 4. ì‘ë‹µ ìƒì„±
        response = self.llm.invoke(messages)
        return docs, response.content

    def initialize_all(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë¬¸ì„œ ë¡œë“œ, ë²¡í„°DB, LLM)"""
        print("=" * 60)
        print("ğŸš€ Google API RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘ (GPT-4o ì „ìš©)")
        print("=" * 60)

        self.load_api_documents()
        self.initialize_vectorstore()
        self.initialize_llm()

        print("\n" + "=" * 60)
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ! ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 60 + "\n")

    def search(self, query: str, verbose: bool = True) -> str:
        """API ê²€ìƒ‰ ë° ì‘ë‹µ ì œê³µì„ ìœ„í•œ ë©”ì¸ ë©”ì†Œë“œ"""
        docs, response = self.generate_response(query)

        if verbose:
            print("\n" + "=" * 60)
            print(f"ğŸ” ì§ˆë¬¸: {query}")
            print("=" * 60)

            print("\nğŸ“š ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ (ìƒìœ„ 3ê°œ):")
            if not docs:
                print("  ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            for i, doc in enumerate(docs[:3], 1):
                category = doc.metadata.get('api_category', 'N/A')
                source = doc.metadata.get('source_file', 'N/A')
                print(f"\n  [{i}] ì¶œì²˜: {source} (ì¹´í…Œê³ ë¦¬: {category})")
                print(f"      ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100].replace(os.linesep, ' ')}...")

            print("\n" + "-" * 60)
            print("ğŸ’¡ ìƒì„±ëœ ë‹µë³€:")
            print("-" * 60)
            print(response)
            print("=" * 60 + "\n")

        return response


# --- ë©”ì¸ ì‹¤í–‰ ì½”ë“œ ---
if __name__ == "__main__":
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
    # 1. í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    # 2. .env íŒŒì¼ì´ ìˆë‹¤ë©´ ê±°ê¸°ì„œ ì°¾ìŠµë‹ˆë‹¤.
    # 3. ëª¨ë‘ ì—†ë‹¤ë©´ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì…ë ¥ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì—¬ê¸°ì„œëŠ” ì˜¤ë¥˜ ë°œìƒ).
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'OPENAI_API_KEY' í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

    # RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì´ˆê¸°í™”
    try:
        rag_system = GoogleAPIRAGSystem(
            api_data_dir='../GOOGLE_API_DATA',
            db_dir='../chroma_google_api_db_gpt',
            openai_api_key=api_key
        )
        rag_system.initialize_all()

        # ëŒ€í™”í˜• ëª¨ë“œë¡œ ì§ˆë¬¸/ë‹µë³€ ì‹œì‘
        print("ğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        while True:
            user_query = input("\nâ“ ì§ˆë¬¸: ").strip()
            if user_query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            if not user_query:
                continue

            rag_system.search(user_query)

    except Exception as e:
        print(f"ğŸ’¥ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")