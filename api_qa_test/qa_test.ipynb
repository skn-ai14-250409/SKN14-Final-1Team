{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## qa셋 전처리 방식별 데이터 정합도/커버율 테스트",
   "id": "7553838f91f59bb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T07:57:28.586548Z",
     "start_time": "2025-08-21T07:57:21.172571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_key_points(text):\n",
    "    prompt = f\"다음 문서에서 핵심적인 기술 포인트 5~10개를 뽑아주세요. 각 포인트는 간결하게 1~2문장으로 작성해 주세요.\\n\\n{text}\"\n",
    "\n",
    "    # GPT-4o-mini 모델로 핵심 포인트 생성 요청\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 모델 이름 (예시: GPT-4o-mini, 원하는 모델을 사용)\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # 시스템 메시지\n",
    "                  {\"role\": \"user\", \"content\": prompt}],  # 사용자 메시지 (핵심 포인트 요청)\n",
    "        max_tokens=500,\n",
    "        temperature=0.\n",
    "    )\n",
    "\n",
    "    # 응답에서 핵심 포인트 추출\n",
    "    key_points = response.choices[0].message.content.strip()\n",
    "\n",
    "    return key_points\n",
    "\n",
    "def save_key_points_to_file(key_points, filename=\"key_points.txt\"):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(key_points)\n",
    "\n",
    "def process_sample_document(file_path):\n",
    "    # 샘플 문서 파일을 읽어 텍스트 추출\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sample_text = file.read()\n",
    "\n",
    "    # 핵심 포인트 생성\n",
    "    key_points = generate_key_points(sample_text)\n",
    "\n",
    "    # 생성된 핵심 포인트를 텍스트 파일로 저장\n",
    "    output_filename = f\"key_points_{os.path.basename(file_path)}.txt\"\n",
    "    save_key_points_to_file(key_points, filename=output_filename)\n",
    "\n",
    "    print(f\"핵심 포인트가 '{output_filename}' 파일에 저장되었습니다.\")\n",
    "\n",
    "# 샘플 문서 경로를 입력받아 해당 문서에 대해 처리\n",
    "sample_document_path = \"./people_quickstart_go.txt\"  # 여기에 경로를 입력하세요\n",
    "process_sample_document(sample_document_path)"
   ],
   "id": "1b47ac7ade02a97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "핵심 포인트가 'key_points_people_quickstart_go.txt.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:06:00.144665Z",
     "start_time": "2025-08-21T08:05:44.933866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# 파일이 저장된 디렉토리 경로\n",
    "files_dir = './test'\n",
    "\n",
    "\n",
    "# 질문-답변 및 출처 생성 함수 (한 번에 처리)\n",
    "def generate_qa_and_sources(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"주어진 People api 문서를 바탕으로 유용한 질문-답변과 해당 답변의 출처 URL을 찾아주세요.\n",
    "\n",
    "**중요한 제약사항:**\n",
    "- 문서에 명시된 내용만을 기반으로 질문과 답변을 작성하세요\n",
    "- 문서에 없는 내용이나 추측, 일반적인 지식을 추가하지 마세요\n",
    "- 답변은 반드시 문서 내용을 직접 참조해야 합니다\n",
    "- 확실하지 않은 내용은 포함하지 마세요\n",
    "\n",
    "**우선적으로 다룰 주제:**\n",
    "1. 코드 예시와 구현 방법\n",
    "2. API 사용법과 파라미터 설명\n",
    "3. 오류 해결 방법과 문제 해결책\n",
    "4. 설정 방법과 구성 옵션\n",
    "5. 실제 사용 사례와 예제\n",
    "\n",
    "**생성 규칙:**\n",
    "- 문서에서 위 주제에 해당하는 내용이 충분히 있을 때만 질문-답변을 생성하세요\n",
    "- 내용이 부족하거나 추상적인 설명만 있다면 \"생성할 수 없음\"이라고 응답하세요\n",
    "- 최대 10개의 질문-답변을 생성하세요\n",
    "- 각 질문-답변은 실용적이고 구체적이어야 합니다\n",
    "\n",
    "**출처 URL 찾기 규칙:**\n",
    "1. 문서 맨 위에 있는 페이지 URL을 기본으로 포함\n",
    "2. 답변 내용과 직접 관련된 특정 섹션이나 기능의 URL이 문서 내에 별도로 명시되어 있다면 추가로 포함\n",
    "3. 내부 링크나 참조 링크가 답변과 관련이 있다면 포함\n",
    "4. 문서에 실제로 존재하는 URL만 사용하세요\n",
    "\n",
    "**응답 형식:**\n",
    "질문1: [문서 내용 기반의 구체적인 질문]\n",
    "답변1: [문서에 명시된 내용만으로 작성한 답변]\n",
    "출처1: [문서 내에 실제로 존재하는 URL1, URL2, ...]\n",
    "\n",
    "질문2: [두 번째 질문]\n",
    "답변2: [두 번째 답변]\n",
    "출처2: [URL1, URL2, ...]\n",
    "\n",
    "(최대 10개까지)\n",
    "\n",
    "만약 적절한 코드 예시나 사용법, 오류 해결법, 설정 방법 등이 문서에 충분히 없다면 \"생성할 수 없음\"이라고만 응답하세요.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"다음 구글 api의 People api 관련 문서를 정확히 분석해서, 코드 예시, 사용법, 오류 해결법 등 실용적인 내용을 기반으로 최대 10개의 질문-답변과 해당 출처 URL들을 찾아주세요. 적절한 내용이 없다면 '생성할 수 없음'이라고 응답하세요:\\n\\n{text}\"\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=2000,\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"질문-답변 및 출처 생성 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_single_qa_block(block):\n",
    "    \"\"\"단일 질문-답변-출처 블록 파싱\"\"\"\n",
    "    try:\n",
    "        qa_dict = {}\n",
    "        lines = block.strip().split('\\n')\n",
    "\n",
    "        current_section = None\n",
    "        question_lines = []\n",
    "        answer_lines = []\n",
    "        source_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # 질문 시작 패턴\n",
    "            if re.match(r'^질문\\d*:', line):\n",
    "                current_section = 'question'\n",
    "                question_content = re.sub(r'^질문\\d*:', '', line).strip()\n",
    "                if question_content:\n",
    "                    question_lines.append(question_content)\n",
    "\n",
    "            # 답변 시작 패턴\n",
    "            elif re.match(r'^답변\\d*:', line):\n",
    "                current_section = 'answer'\n",
    "                answer_content = re.sub(r'^답변\\d*:', '', line).strip()\n",
    "                if answer_content:\n",
    "                    answer_lines.append(answer_content)\n",
    "\n",
    "            # 출처 시작 패턴\n",
    "            elif re.match(r'^출처\\d*:', line):\n",
    "                current_section = 'sources'\n",
    "                source_content = re.sub(r'^출처\\d*:', '', line).strip()\n",
    "                if source_content:\n",
    "                    source_lines.append(source_content)\n",
    "\n",
    "            # 연속되는 내용 라인\n",
    "            else:\n",
    "                if current_section == 'question':\n",
    "                    question_lines.append(line)\n",
    "                elif current_section == 'answer':\n",
    "                    answer_lines.append(line)\n",
    "                elif current_section == 'sources':\n",
    "                    source_lines.append(line)\n",
    "\n",
    "        # 각 섹션 조합\n",
    "        if question_lines:\n",
    "            qa_dict['question'] = ' '.join(question_lines).strip()\n",
    "\n",
    "        if answer_lines:\n",
    "            qa_dict['answer'] = ' '.join(answer_lines).strip()\n",
    "\n",
    "        # URL은 그대로 사용 (중복 파싱 제거)\n",
    "        if source_lines:\n",
    "            # AI가 이미 주는 URL을 그대로 분리\n",
    "            urls = []\n",
    "            for s in source_lines:\n",
    "                urls.extend([u.strip() for u in s.split() if u.startswith(\"http\")])\n",
    "            qa_dict['sources'] = urls if urls else [\"출처를 찾을 수 없음\"]\n",
    "        else:\n",
    "            qa_dict['sources'] = [\"출처를 찾을 수 없음\"]\n",
    "\n",
    "        return qa_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"단일 QA 블록 파싱 중 오류: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# AI 응답을 파싱하는 함수 (개선된 버전)\n",
    "def parse_qa_and_sources(ai_response):\n",
    "    \"\"\"개선된 질문-답변-출처 파싱 함수\"\"\"\n",
    "    try:\n",
    "        # \"생성할 수 없음\" 응답 체크\n",
    "        if \"생성할 수 없음\" in ai_response:\n",
    "            print(\"  -> 적절한 내용이 없어서 질문-답변을 생성하지 않음\")\n",
    "            return []\n",
    "\n",
    "        qa_pairs = []\n",
    "\n",
    "        # 전체 텍스트를 질문 단위로 분할\n",
    "        # 질문1:, 질문2: 등의 패턴으로 분할\n",
    "        question_blocks = re.split(r'\\n(?=질문\\d*:)', ai_response.strip())\n",
    "\n",
    "        for block in question_blocks:\n",
    "            if not block.strip():\n",
    "                continue\n",
    "\n",
    "            # 각 블록에서 질문, 답변, 출처 추출\n",
    "            qa_dict = parse_single_qa_block(block)\n",
    "            if qa_dict and qa_dict.get('question') and qa_dict.get('answer'):\n",
    "                # 데이터 정리\n",
    "                cleaned_qa = {\n",
    "                    'question': qa_dict['question'].strip(),\n",
    "                    'answer': qa_dict['answer'].strip(),\n",
    "                    'sources': qa_dict.get('sources', [\"출처를 찾을 수 없음\"])\n",
    "                }\n",
    "                qa_pairs.append(cleaned_qa)\n",
    "\n",
    "        print(f\"  -> 파싱된 QA 쌍 개수: {len(qa_pairs)}\")\n",
    "        return qa_pairs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"응답 파싱 중 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# 메인 처리 함수\n",
    "def process_files_and_generate_jsonl():\n",
    "    jsonl_data = []\n",
    "\n",
    "    for filename in os.listdir(files_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(files_dir, filename)\n",
    "            print(f\"처리 중: {filename}\")\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # AI가 질문-답변과 출처를 한 번에 생성\n",
    "            ai_response = generate_qa_and_sources(text)\n",
    "            if ai_response:\n",
    "                # AI 응답 파싱 (여러 개의 질문-답변 쌍)\n",
    "                qa_pairs = parse_qa_and_sources(ai_response)\n",
    "\n",
    "                if qa_pairs:\n",
    "                    print(f\"  -> {len(qa_pairs)}개의 질문-답변 쌍 생성됨\")\n",
    "                    for i, qa in enumerate(qa_pairs, 1):\n",
    "                        print(f\"    질문{i}: {qa['question'][:50]}...\")\n",
    "                        print(f\"    출처{i}: {qa['sources']}\")\n",
    "\n",
    "                        # 메타데이터 설정\n",
    "                        metadata = {\n",
    "                            \"question\": qa['question'],\n",
    "                            \"answer\": qa['answer'],\n",
    "                            \"sources\": qa['sources'],\n",
    "                            \"tags\": \"people\",\n",
    "                            \"last_verified\": \"2025-08-19\",\n",
    "                            \"source_file\": filename\n",
    "                        }\n",
    "                        jsonl_data.append(metadata)\n",
    "                else:\n",
    "                    print(f\"  -> 적절한 내용이 없어서 건너뛰기: {filename}\")\n",
    "            else:\n",
    "                print(f\"  -> AI 응답 실패: {filename}\")\n",
    "\n",
    "    # JSONL 파일로 저장\n",
    "    jsonl_filename = 'people_test_generated_qa.jsonl'\n",
    "    with open(jsonl_filename, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for item in jsonl_data:\n",
    "            jsonl_file.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"\\n완료! 총 {len(jsonl_data)}개의 질문-답변 쌍이 {jsonl_filename}에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    process_files_and_generate_jsonl()\n"
   ],
   "id": "91d427ada6dc2ae8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 중: people_quickstart_go.txt\n",
      "  -> 파싱된 QA 쌍 개수: 10\n",
      "  -> 10개의 질문-답변 쌍 생성됨\n",
      "    질문1: People API를 사용하기 위해 필요한 기본 요건은 무엇인가요?...\n",
      "    출처1: ['https://developers.google.com/people/quickstart/go?hl=ko#prerequisites']\n",
      "    질문2: Google Cloud 프로젝트에서 People API를 사용 설정하는 방법은 무엇인가요?...\n",
      "    출처2: ['https://developers.google.com/people/quickstart/go?hl=ko#enable_the_api']\n",
      "    질문3: OAuth 동의 화면을 구성하는 방법은 무엇인가요?...\n",
      "    출처3: ['https://developers.google.com/people/quickstart/go?hl=ko#configure_the_oauth_consent_screen']\n",
      "    질문4: 데스크톱 애플리케이션의 사용자 인증 정보를 승인하는 방법은 무엇인가요?...\n",
      "    출처4: ['https://developers.google.com/people/quickstart/go?hl=ko#authorize_credentials_for_a_desktop_application']\n",
      "    질문5: People API를 호출하는 Go 애플리케이션의 샘플 코드는 어떻게 작성하나요?...\n",
      "    출처5: ['https://developers.google.com/people/quickstart/go?hl=ko#set_up_the_sample']\n",
      "    질문6: 샘플 애플리케이션을 실행하는 방법은 무엇인가요?...\n",
      "    출처6: ['https://developers.google.com/people/quickstart/go?hl=ko#run_the_sample']\n",
      "    질문7: People API를 통해 사용자의 연결 목록을 가져오는 방법은 무엇인가요?...\n",
      "    출처7: ['https://developers.google.com/people/quickstart/go?hl=ko#run_the_sample']\n",
      "    질문8: 인증 및 승인 문제를 해결하는 방법은 무엇인가요?...\n",
      "    출처8: ['https://developers.google.com/people/v1/troubleshoot-authentication-authorization?hl=ko']\n",
      "    질문9: People API의 참조 문서는 어디에서 찾을 수 있나요?...\n",
      "    출처9: ['https://developers.google.com/people/api?hl=ko']\n",
      "    질문10: People API Go 클라이언트 라이브러리를 설치하는 방법은 무엇인가요?...\n",
      "    출처10: ['https://developers.google.com/people/quickstart/go?hl=ko#prepare_the_workspace']\n",
      "\n",
      "완료! 총 10개의 질문-답변 쌍이 people_test_generated_qa.jsonl에 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:08:03.044131Z",
     "start_time": "2025-08-21T08:07:28.197209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import datetime\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "ROOT_DIR = \"./test\"   # 재귀 순회할 최상위 폴더\n",
    "OUT_JSONL = \"./people_test_generated_qa_edit.jsonl\"         # 결과를 저장할 JSONL 파일\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "PAIR_MAX_QA = 5                          # 페어(또는 단일 청크)당 최대 Q&A 개수\n",
    "CHUNK_TOKENS = 900                       # 청크 크기(토큰 기준)\n",
    "CHUNK_OVERLAP_TOKENS = 150                # 청크 오버랩(토큰 기준)\n",
    "PAIR_WINDOW = 2                          # 연속 청크 페어 크기\n",
    "MAX_CONTEXT_TOKENS = 4096                # 모델 컨텍스트 상한\n",
    "MAX_RETRY = 4                            # API 재시도 횟수\n",
    "\n",
    "client = OpenAI()                         # OPENAI_API_KEY 필요\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# =========================\n",
    "# 유틸\n",
    "# =========================\n",
    "def parse_source_meta(text):\n",
    "    \"\"\"문서 상단에서 Source URL 추출.\"\"\"\n",
    "    head = text[:2000]  # 문서 상단에서 첫 2000자만 처리\n",
    "    m_url = re.search(r'(?i)^Source\\s*URL\\s*:\\s*(\\S+)', head, flags=re.M)\n",
    "    return m_url.group(1).strip() if m_url else None\n",
    "\n",
    "def smart_split(text):\n",
    "    \"\"\"토큰 기반 청킹 + 오버랩.\"\"\"\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    toks = enc.encode(text)  # tiktoken으로 텍스트를 토큰으로 변환\n",
    "    chunks = []\n",
    "    step = max(1, CHUNK_TOKENS - CHUNK_OVERLAP_TOKENS)\n",
    "    for i in range(0, len(toks), step):\n",
    "        block = toks[i:i + CHUNK_TOKENS]  # 청크 크기만큼 자르기\n",
    "        if not block: break\n",
    "        chunk_text = enc.decode(block).strip()\n",
    "        if chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "    return chunks\n",
    "\n",
    "def make_pairs(chunks, window=PAIR_WINDOW):\n",
    "    \"\"\"연속 청크 페어 목록 생성: (0,[0,1]), (1,[1,2]), …\"\"\"\n",
    "    if window < 2 or len(chunks) < 2:\n",
    "        return []\n",
    "    return [(i, chunks[i:i+window]) for i in range(len(chunks) - (window - 1))]\n",
    "\n",
    "def trim_to_context_limit(text):\n",
    "    \"\"\"컨텍스트 초과 시 텍스트를 토큰 기준으로 상한 내로 자름.\"\"\"\n",
    "    toks = enc.encode(text)\n",
    "    if len(toks) <= MAX_CONTEXT_TOKENS:\n",
    "        return text\n",
    "    return enc.decode(toks[:MAX_CONTEXT_TOKENS])\n",
    "\n",
    "def hash_id(*parts):\n",
    "    \"\"\"안정적 레코드 ID 생성.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    for p in parts:\n",
    "        h.update((p or \"\").encode(\"utf-8\")); h.update(b\"|\")\n",
    "    return h.hexdigest()[:32]\n",
    "\n",
    "def json_loads_strict_or_strip_codefence(s):\n",
    "    \"\"\"\n",
    "    response_format=json_object 덕분에 보통은 바로 json.loads로 충분.\n",
    "    혹시 모를 코드펜스(```json ... ```)만 제거하는 얇은 래퍼.\n",
    "    \"\"\"\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", s, flags=re.I|re.S)\n",
    "    return json.loads(s)\n",
    "\n",
    "# =========================\n",
    "# 모델 호출\n",
    "# =========================\n",
    "def ask_model(pair_text, n, source_url):\n",
    "    \"\"\"\n",
    "    해당 텍스트 범위에서 Q&A n개(JSON) 생성. 없으면 빈 리스트 반환.\n",
    "    - 문서 범위 밖 정보 금지\n",
    "    - 실무 친화적 질문/정확한 답변\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        return []\n",
    "\n",
    "    system_prompt = (\n",
    "        \"당신은 구글 API 중 PEOPLE API의 공식 문서 텍스트에서만 근거를 삼아 Q&A를 만듭니다. \"\n",
    "        \"문서에 명시된 내용만 사용하고 추측은 금지합니다. 실무자가 바로 쓰도록 자세하고 이해하기 쉽게 답변해주세요.\"\n",
    "    )\n",
    "    url_hint = f\"\\n- 참고 URL(있으면): {source_url}\" if source_url else \"\"\n",
    "    user_prompt = f\"\"\"\n",
    "아래는 한 문서의 (연속) 청크 범위입니다. 이 범위에서만 Q&A {n}개를 JSON으로 만들어 주세요.\n",
    "\n",
    "\n",
    "\n",
    "**요구사항:**\n",
    "- 문서 범위를 벗어난 정보 금지\n",
    "- 질문은 실무 친화적으로 구체적·명확하게\n",
    "- 답변은 문서 용어/표기 준수\n",
    "- 각 항목: question, answer\n",
    "\n",
    "**중요한 제약사항:**\n",
    "- 문서에 명시된 내용만을 기반으로 질문과 답변을 작성하세요\n",
    "- 문서에 없는 내용이나 추측, 일반적인 지식을 추가하지 마세요\n",
    "- 답변은 반드시 문서 내용을 직접 참조해야 합니다\n",
    "- 확실하지 않은 내용은 포함하지 마세요\n",
    "- 만약 적절한 코드 예시나 사용법, 오류 해결법, 설정 방법 등이 문서에 충분히 없다면 \"생성할 수 없음\"이라고만 응답하세요.\n",
    "\n",
    "**우선적으로 다룰 주제:**\n",
    "1. 코드 예시와 구현 방법\n",
    "2. API 사용법과 파라미터 설명\n",
    "3. 오류 해결 방법과 문제 해결책\n",
    "4. 설정 방법과 구성 옵션\n",
    "5. 실제 사용 사례와 예제\n",
    "\n",
    "{url_hint}\n",
    "\n",
    "[원문 시작]\n",
    "{pair_text}\n",
    "[원문 끝]\n",
    "\n",
    "JSON 스키마:\n",
    "{{\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"question\": \"…\",\n",
    "      \"answer\": \"…\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    for attempt in range(1, MAX_RETRY + 1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"},  # JSON 강제\n",
    "                temperature=0.,\n",
    "                max_tokens=1100,\n",
    "            )\n",
    "            data = json_loads_strict_or_strip_codefence(resp.choices[0].message.content)\n",
    "            items = data.get(\"items\", []) if isinstance(data, dict) else []\n",
    "            return items[:n]  # 과도 생성 시 컷\n",
    "        except Exception:\n",
    "            if attempt == MAX_RETRY:\n",
    "                return []\n",
    "            time.sleep(0.8 * attempt)  # 간단 백오프\n",
    "\n",
    "# =========================\n",
    "# 문서 처리\n",
    "# =========================\n",
    "def build_record(q, a, doc_path, pair_index,\n",
    "                 chunk_indices, passage_window,\n",
    "                 source_url):\n",
    "    \"\"\"RAG 친화 JSON 레코드.\"\"\"\n",
    "    rid = hash_id(doc_path, str(pair_index), q, a)  # 고유 레코드 ID 생성\n",
    "    return {\n",
    "        \"question\": q.strip(),  # 질문\n",
    "        \"answer\": a.strip(),  # 답변\n",
    "        \"sources\": [source_url or f\"file://{doc_path}\"],   # Source URL\n",
    "        \"tags\": \"people\",                                  # 고정\n",
    "        \"last_verified\": \"2025-08-19\",                      # 고정\n",
    "        \"source_file\": os.path.basename(doc_path),          # 파일 이름\n",
    "    }\n",
    "\n",
    "def process_one_file(file_path, out_fh):\n",
    "    \"\"\"\n",
    "    단일 문서 처리:\n",
    "    - 상단 메타(Source URL) 추출 → 토큰 청킹\n",
    "    - 청크=1이면 그 1개로 최대 5개 생성\n",
    "    - 청크>=2면 (연속 페어)마다 최대 5개 생성\n",
    "    - 생성 없으면 스킵, 결과는 JSONL append\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:  # 파일 열기\n",
    "        text = f.read()  # 파일 내용 읽기\n",
    "    if not text.strip():  # 비어 있는 파일은 처리하지 않음\n",
    "        return 0\n",
    "\n",
    "    source_url = parse_source_meta(text)  # Source URL 추출\n",
    "    chunks = smart_split(text)  # 텍스트를 청크로 나누기\n",
    "    written = 0  # 작성된 Q&A 수 초기화\n",
    "\n",
    "    # (A) 청크가 1개뿐 → 그 1개로 최대 5개 생성\n",
    "    if len(chunks) == 1:\n",
    "        pair_text = trim_to_context_limit(chunks[0])  # 청크 텍스트 크기 제한\n",
    "        items = ask_model(pair_text, PAIR_MAX_QA, source_url)  # Q&A 생성\n",
    "        for it in items:\n",
    "            q, a = (it.get(\"question\") or \"\").strip(), (it.get(\"answer\") or \"\").strip()  # Q&A 추출\n",
    "            if not q or not a: continue  # 질문과 답변이 없으면 건너뜀\n",
    "            rec = build_record(q, a, file_path, 0, [0], pair_text, source_url)  # Q&A 레코드 생성\n",
    "            out_fh.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")  # JSONL에 저장\n",
    "            written += 1  # 작성된 Q&A 수 증가\n",
    "        return written\n",
    "\n",
    "    # (B) 청크가 2개 이상 → (1,2), (2,3)… 페어마다 최대 5개 생성\n",
    "    pairs = make_pairs(chunks, window=PAIR_WINDOW)  # 청크 페어 생성\n",
    "    if not pairs:  # 페어가 없다면 스킵\n",
    "        return 0\n",
    "\n",
    "    for (pair_idx, cg) in pairs:  # 각 페어에 대해\n",
    "        pair_text = trim_to_context_limit(\"\\n\\n---\\n\\n\".join(cg))  # 청크 페어 텍스트 크기 제한\n",
    "        items = ask_model(pair_text, PAIR_MAX_QA, source_url)  # Q&A 생성\n",
    "        if not items:  # Q&A가 없다면 스킵\n",
    "            continue\n",
    "        chunk_indices = list(range(pair_idx, pair_idx + len(cg)))  # 청크 인덱스 생성\n",
    "        for it in items:\n",
    "            q, a = (it.get(\"question\") or \"\").strip(), (it.get(\"answer\") or \"\").strip()  # Q&A 추출\n",
    "            if not q or not a: continue  # 질문과 답변이 없으면 건너뜀\n",
    "            rec = build_record(q, a, file_path, pair_idx, chunk_indices, pair_text, source_url)  # Q&A 레코드 생성\n",
    "            out_fh.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")  # JSONL에 저장\n",
    "            written += 1  # 작성된 Q&A 수 증가\n",
    "\n",
    "    return written\n",
    "\n",
    "# =========================\n",
    "# 엔트리포인트\n",
    "# =========================\n",
    "def walk_and_generate():\n",
    "    \"\"\"폴더 재귀 순회 → 모든 문서를 처리 → 하나의 JSONL로 누적 저장.\"\"\"\n",
    "    os.makedirs(os.path.dirname(OUT_JSONL) or \".\", exist_ok=True)  # 저장할 폴더 생성\n",
    "    total_docs, total_qas = 0, 0  # 총 문서와 Q&A 수 초기화\n",
    "    with open(OUT_JSONL, \"a\", encoding=\"utf-8\") as out_fh:  # JSONL 파일 열기 (append 모드)\n",
    "        for root, _, files in os.walk(ROOT_DIR):  # ROOT_DIR 내 모든 파일 재귀 순회\n",
    "            for name in files:  # 각 파일에 대해\n",
    "                if not name.lower().endswith(\".txt\"): continue  # .txt 파일만 처리\n",
    "                path = os.path.join(root, name)  # 파일 경로 만들기\n",
    "                print(f\"[DOC] {path}\")  # 파일 경로 출력\n",
    "                cnt = process_one_file(path, out_fh)  # 파일 처리 후 Q&A 수 반환\n",
    "                print(f\"  -> {cnt} QAs\")  # 처리된 Q&A 수 출력\n",
    "                total_docs += 1  # 문서 수 증가\n",
    "                total_qas += cnt  # Q&A 수 증가\n",
    "    print(f\"\\n[DONE] docs={total_docs}, qas={total_qas}, out={OUT_JSONL}\")  # 전체 처리 결과 출력\n",
    "\n",
    "\n",
    "walk_and_generate()"
   ],
   "id": "931d348ce21e8c86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOC] ./test\\people_quickstart_go.txt\n",
      "  -> 20 QAs\n",
      "\n",
      "[DONE] docs=1, qas=20, out=./people_test_generated_qa_edit.jsonl\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:12:14.026563Z",
     "start_time": "2025-08-21T08:11:59.444341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_coverage_report(key_points, qa_set):\n",
    "    # LLM 평가 프롬프트 생성\n",
    "    prompt = \"다음은 샘플 문서에 대한 핵심 포인트입니다. 각 포인트가 아래 QA셋에 얼마나 잘 반영되었는지 평가해주세요.\\n\\n\"\n",
    "\n",
    "    # 핵심 포인트 추가\n",
    "    for idx, point in enumerate(key_points, 1):\n",
    "        prompt += f\"{idx}. {point}\\n\"\n",
    "\n",
    "    # QA셋 추가\n",
    "    prompt += \"\\n다음은 QA셋입니다:\\n\"\n",
    "    for idx, qa in enumerate(qa_set, 1):\n",
    "        prompt += f\"{idx}. Q: {qa['question']} A: {qa['answer']}\\n\"\n",
    "\n",
    "    prompt += \"\\n각 핵심 포인트가 QA셋에서 반영되었는지 평가해 주세요. 반영 여부를 '반영됨', '부분 반영됨', '누락됨'으로 알려주세요.\"\n",
    "\n",
    "    # GPT 모델로 평가 요청\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 사용할 모델\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # 시스템 메시지\n",
    "                  {\"role\": \"user\", \"content\": prompt}],  # 사용자 메시지 (핵심 포인트 및 QA셋)\n",
    "        max_tokens=1000,\n",
    "        temperature=0.\n",
    "    )\n",
    "\n",
    "    # 응답에서 결과 추출\n",
    "    evaluation = response.choices[0].message.content.strip()\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def load_key_points_from_file(filename):\n",
    "    # 저장된 핵심 포인트 텍스트 파일을 읽어서 반환\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        key_points = file.read().strip().split('\\n')\n",
    "    return key_points\n",
    "\n",
    "def load_qa_set_from_jsonl(filename):\n",
    "    # JSONL 파일에서 QA셋을 로드\n",
    "    qa_set = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            qa_set.append(json.loads(line))\n",
    "    return qa_set\n",
    "\n",
    "# 핵심 포인트 파일과 QA셋 파일 경로\n",
    "key_points_file = \"key_points_people_quickstart_go.txt\"\n",
    "qa_set_file = \"people_test_generated_qa.jsonl\"\n",
    "qa_set_file_edit = \"people_test_generated_qa_edit.jsonl\"\n",
    "\n",
    "# 핵심 포인트와 QA셋 불러오기\n",
    "key_points = load_key_points_from_file(key_points_file)\n",
    "qa_set = load_qa_set_from_jsonl(qa_set_file)\n",
    "qa_set_edit = load_qa_set_from_jsonl(qa_set_file_edit)\n",
    "\n",
    "# LLM을 사용한 평가\n",
    "evaluation_result = generate_coverage_report(key_points, qa_set)\n",
    "evaluation_result_edit = generate_coverage_report(key_points, qa_set_edit)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"기본 전처리 LLM 평가 결과:\\n\", evaluation_result)\n",
    "print(\"수정 전처리 LLM 평가 결과:\\n\", evaluation_result_edit)\n"
   ],
   "id": "d9d4066c3ca313b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 전처리 LLM 평가 결과:\n",
      " 각 핵심 포인트가 QA셋에서 반영되었는지 평가한 결과는 다음과 같습니다:\n",
      "\n",
      "1. **목표 설정**: 반영됨\n",
      "   - QA셋의 질문들은 People API를 사용하는 방법에 대한 정보를 제공하고 있으며, 목표 설정의 내용이 잘 반영되어 있습니다.\n",
      "\n",
      "2. **기본 요건**: 반영됨\n",
      "   - QA셋의 첫 번째 질문에서 기본 요건이 명확하게 언급되어 있습니다.\n",
      "\n",
      "3. **API 사용 설정**: 반영됨\n",
      "   - QA셋의 두 번째 질문에서 Google Cloud 프로젝트에서 People API를 사용 설정하는 방법이 잘 설명되어 있습니다.\n",
      "\n",
      "4. **OAuth 동의 화면 구성**: 반영됨\n",
      "   - QA셋의 세 번째 질문에서 OAuth 동의 화면 구성 방법이 상세히 설명되어 있습니다.\n",
      "\n",
      "5. **클라이언트 ID 생성**: 부분 반영됨\n",
      "   - QA셋의 네 번째 질문에서 클라이언트 ID 생성 방법이 언급되지만, OAuth 2.0 클라이언트 ID 생성에 대한 구체적인 내용이 부족합니다.\n",
      "\n",
      "6. **작업 디렉터리 설정**: 누락됨\n",
      "   - QA셋에는 작업 디렉터리 설정에 대한 질문이 없습니다.\n",
      "\n",
      "7. **샘플 코드 작성**: 반영됨\n",
      "   - QA셋의 다섯 번째 질문에서 샘플 코드 작성 방법이 잘 설명되어 있습니다.\n",
      "\n",
      "8. **샘플 실행**: 반영됨\n",
      "   - QA셋의 여섯 번째 질문에서 샘플 애플리케이션 실행 방법이 명확하게 설명되어 있습니다.\n",
      "\n",
      "9. **토큰 저장**: 누락됨\n",
      "   - QA셋에는 토큰 저장에 대한 질문이 없습니다.\n",
      "\n",
      "10. **문제 해결**: 반영됨\n",
      "    - QA셋의 여덟 번째 질문에서 인증 및 승인 문제 해결 방법이 잘 설명되어 있습니다.\n",
      "\n",
      "종합적으로 평가하면, 일부 핵심 포인트는 잘 반영되었고, 몇 가지는 부분적으로 반영되거나 누락되었습니다.\n",
      "수정 전처리 LLM 평가 결과:\n",
      " 각 핵심 포인트가 QA셋에서 반영되었는지 평가한 결과는 다음과 같습니다:\n",
      "\n",
      "1. **목표 설정**: 반영됨\n",
      "   - QA셋의 5번 질문이 이 목표를 잘 반영하고 있습니다.\n",
      "\n",
      "2. **기본 요건**: 반영됨\n",
      "   - QA셋의 1번 질문이 기본 요건을 잘 설명하고 있습니다.\n",
      "\n",
      "3. **API 사용 설정**: 반영됨\n",
      "   - QA셋의 2번 질문과 6번 질문이 API 사용 설정 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "4. **OAuth 동의 화면 구성**: 반영됨\n",
      "   - QA셋의 3번 질문과 7번 질문이 OAuth 동의 화면 구성 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "5. **클라이언트 ID 생성**: 반영됨\n",
      "   - QA셋의 4번 질문과 8번 질문이 클라이언트 ID 생성 과정을 잘 설명하고 있습니다.\n",
      "\n",
      "6. **작업 디렉터리 설정**: 부분 반영됨\n",
      "   - QA셋의 9번 질문과 12번 질문이 작업 디렉터리 설정 방법을 설명하고 있지만, Go 모듈 초기화에 대한 언급이 부족합니다.\n",
      "\n",
      "7. **샘플 코드 작성**: 부분 반영됨\n",
      "   - QA셋의 14번 질문이 샘플 코드 실행 방법을 설명하고 있지만, 샘플 코드 작성에 대한 구체적인 내용은 누락되어 있습니다.\n",
      "\n",
      "8. **샘플 실행**: 반영됨\n",
      "   - QA셋의 14번 질문이 샘플 실행 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "9. **토큰 저장**: 반영됨\n",
      "   - QA셋의 19번 질문이 인증 정보를 파일에 저장하는 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "10. **문제 해결**: 반영됨\n",
      "    - QA셋의 15번 질문이 인증 및 승인 문제 해결을 위한 리소스를 잘 설명하고 있습니다.\n",
      "\n",
      "종합적으로 평가하면, 대부분의 핵심 포인트가 QA셋에 잘 반영되었으나, 일부는 부분적으로만 반영되었거나 구체적인 내용이 누락된 경우가 있습니다.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T08:38:38.805557Z",
     "start_time": "2025-08-21T08:38:28.179414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_coverage_report(key_points, qa_set):\n",
    "    # LLM 평가 프롬프트 생성\n",
    "    prompt = \"다음은 샘플 문서에 대한 핵심 포인트입니다. 각 포인트가 아래 QA셋에 얼마나 잘 반영되었는지 평가해주세요.\\n\\n\"\n",
    "\n",
    "    # 핵심 포인트 추가 (10개로 고정)\n",
    "    for idx, point in enumerate(key_points, 1):\n",
    "        prompt += f\"{idx}. {point}\\n\"\n",
    "\n",
    "    # QA셋 추가\n",
    "    prompt += \"\\n다음은 QA셋입니다:\\n\"\n",
    "    for idx, qa in enumerate(qa_set, 1):\n",
    "        prompt += f\"{idx}. Q: {qa['question']} A: {qa['answer']}\\n\"\n",
    "\n",
    "    prompt += \"\\n각 핵심 포인트가 QA셋에서 반영되었는지 평가해 주세요. 반영 여부를 '반영됨', '부분반영', '누락됨'으로 알려주세요.\"\n",
    "\n",
    "    # GPT 모델로 평가 요청\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 사용할 모델\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # 시스템 메시지\n",
    "                  {\"role\": \"user\", \"content\": prompt}],  # 사용자 메시지 (핵심 포인트 및 QA셋)\n",
    "        max_tokens=1000,\n",
    "        temperature=0.\n",
    "    )\n",
    "\n",
    "    # 응답에서 결과 추출\n",
    "    evaluation = response.choices[0].message.content.strip()\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def load_key_points_from_file(filename):\n",
    "    # 저장된 핵심 포인트 텍스트 파일을 읽어서 반환\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        key_points = file.read().strip().split('\\n')\n",
    "\n",
    "    # 공백 문자열이나 빈 항목을 제거하고 유효한 핵심 포인트만 반환\n",
    "    key_points = [point for point in key_points if point.strip()]  # 공백 제거\n",
    "    return key_points\n",
    "\n",
    "def load_qa_set_from_jsonl(filename):\n",
    "    # JSONL 파일에서 QA셋을 로드\n",
    "    qa_set = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            qa_set.append(json.loads(line))\n",
    "    return qa_set\n",
    "\n",
    "def calculate_coverage_score(key_points, evaluation_result):\n",
    "    \"\"\"\n",
    "    평가 결과에서 '반영됨', '부분 반영', '누락됨'을 기반으로 커버리지를 계산\n",
    "    - 반영됨 = 1점\n",
    "    - 부분 반영됨 = 0.5점\n",
    "    - 누락됨 = 0점\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    total_points = len(key_points)  # 핵심 포인트의 개수는 key_points에서 얻음\n",
    "\n",
    "    # 평가 결과에서 각 핵심 포인트에 대한 반영 상태를 확인하고 점수 계산\n",
    "    for line in evaluation_result.split('\\n'):\n",
    "        if \"반영됨\" in line:\n",
    "            score += 1\n",
    "        elif \"부분반영\" in line:\n",
    "            score += 0.5\n",
    "        # \"누락됨\"은 점수를 더하지 않음\n",
    "\n",
    "    coverage_rate = (score / total_points) * 100\n",
    "    return coverage_rate, score, total_points\n",
    "\n",
    "# 핵심 포인트 파일과 QA셋 파일 경로\n",
    "key_points_file = \"key_points_people_quickstart_go.txt\"\n",
    "qa_set_file = \"people_test_generated_qa.jsonl\"\n",
    "qa_set_file_edit = \"people_test_generated_qa_edit.jsonl\"\n",
    "\n",
    "# 핵심 포인트와 QA셋 불러오기\n",
    "key_points = load_key_points_from_file(key_points_file)\n",
    "qa_set = load_qa_set_from_jsonl(qa_set_file)\n",
    "qa_set_edit = load_qa_set_from_jsonl(qa_set_file_edit)\n",
    "\n",
    "# LLM을 사용한 평가\n",
    "evaluation_result = generate_coverage_report(key_points, qa_set)\n",
    "evaluation_result_edit = generate_coverage_report(key_points, qa_set_edit)\n",
    "\n",
    "# 정량적 커버율 계산\n",
    "coverage_rate, covered_points, total_points = calculate_coverage_score(key_points, evaluation_result)\n",
    "coverage_rate_edit, covered_points_edit, total_points_edit = calculate_coverage_score(key_points, evaluation_result_edit)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"기본 전처리 LLM 평가 결과:\\n\", evaluation_result)\n",
    "print(f\"기본 전처리 커버율: {coverage_rate:.2f}% ({covered_points}/{total_points} 포인트 반영됨)\")\n",
    "\n",
    "print(\"수정 전처리 LLM 평가 결과:\\n\", evaluation_result_edit)\n",
    "print(f\"수정 전처리 커버율: {coverage_rate_edit:.2f}% ({covered_points_edit}/{total_points_edit} 포인트 반영됨)\")\n"
   ],
   "id": "3eb55fd6cf6c0dbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 전처리 LLM 평가 결과:\n",
      " 각 핵심 포인트가 QA셋에서 반영되었는지 평가한 결과는 다음과 같습니다:\n",
      "\n",
      "1. **목표 설정**: 반영됨\n",
      "   - QA셋의 질문과 답변이 Google Workspace API를 호출하는 Go 애플리케이션 설정에 대한 내용을 포함하고 있습니다.\n",
      "\n",
      "2. **기본 요건**: 반영됨\n",
      "   - QA셋의 1번 질문과 답변이 기본 요건을 정확히 반영하고 있습니다.\n",
      "\n",
      "3. **API 사용 설정**: 반영됨\n",
      "   - QA셋의 2번 질문과 답변이 Google Cloud 프로젝트에서 People API를 사용 설정하는 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "4. **OAuth 동의 화면 구성**: 반영됨\n",
      "   - QA셋의 3번 질문과 답변이 OAuth 동의 화면 구성 방법을 상세히 설명하고 있습니다.\n",
      "\n",
      "5. **클라이언트 ID 생성**: 부분반영\n",
      "   - QA셋의 4번 질문과 답변이 클라이언트 ID 생성에 대한 정보를 포함하고 있지만, JSON 파일을 다운로드하여 작업 디렉터리에 저장하는 부분이 명확히 언급되지 않았습니다.\n",
      "\n",
      "6. **작업 디렉터리 설정**: 누락됨\n",
      "   - QA셋에는 작업 디렉터리 설정에 대한 질문과 답변이 없습니다.\n",
      "\n",
      "7. **샘플 코드 작성**: 반영됨\n",
      "   - QA셋의 5번 질문과 답변이 샘플 코드 작성에 대한 내용을 잘 반영하고 있습니다.\n",
      "\n",
      "8. **샘플 실행**: 반영됨\n",
      "   - QA셋의 6번 질문과 답변이 샘플 애플리케이션 실행 방법을 정확히 설명하고 있습니다.\n",
      "\n",
      "9. **토큰 저장**: 누락됨\n",
      "   - QA셋에는 인증 후 토큰 저장에 대한 질문과 답변이 없습니다.\n",
      "\n",
      "10. **문제 해결**: 반영됨\n",
      "    - QA셋의 8번 질문과 답변이 인증 및 승인 문제 해결 방법을 잘 설명하고 있습니다.\n",
      "\n",
      "종합적으로 평가하면, 일부 핵심 포인트는 잘 반영되었으나, 몇 가지는 누락되거나 부분적으로만 반영되었습니다.\n",
      "기본 전처리 커버율: 75.00% (7.5/10 포인트 반영됨)\n",
      "수정 전처리 LLM 평가 결과:\n",
      " 각 핵심 포인트가 QA셋에서 반영되었는지 평가한 결과는 다음과 같습니다:\n",
      "\n",
      "1. **목표 설정**: 반영됨\n",
      "2. **기본 요건**: 반영됨\n",
      "3. **API 사용 설정**: 반영됨\n",
      "4. **OAuth 동의 화면 구성**: 반영됨\n",
      "5. **클라이언트 ID 생성**: 반영됨\n",
      "6. **작업 디렉터리 설정**: 반영됨\n",
      "7. **샘플 코드 작성**: 부분반영 (샘플 코드 작성에 대한 구체적인 내용은 포함되어 있으나, \"샘플 코드 작성\"이라는 포인트가 직접적으로 반영되지는 않음)\n",
      "8. **샘플 실행**: 반영됨\n",
      "9. **토큰 저장**: 반영됨\n",
      "10. **문제 해결**: 반영됨\n",
      "\n",
      "이와 같이 각 포인트에 대한 반영 여부를 평가하였습니다.\n",
      "수정 전처리 커버율: 95.00% (9.5/10 포인트 반영됨)\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
