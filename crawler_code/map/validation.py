import os
import re
import time
from urllib.parse import urljoin, urlparse, parse_qs
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException

# ì‹œì‘ URL
BASE_URL = "https://developers.google.com"
START_URL = "/maps/documentation/address-validation?hl=ko"

# ì €ì¥í•  í´ë” ì´ë¦„
OUTPUT_DIR = "validation"

# ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ë°©ë¬¸í•œ URL ì¶”ì  (ì¤‘ë³µ ë°©ì§€)
visited_urls = set()

# ì…€ë ˆë‹ˆì›€ ì˜µì…˜ ì„¤ì •
chrome_options = Options()
# chrome_options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ì„ ë³´ì§€ ì•Šê³  ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ í•´ì œ
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--window-size=1920,1080")
chrome_options.add_argument("--disable-logging")
chrome_options.add_argument("--disable-logging-redirect")
chrome_options.add_argument("--log-level=3")
chrome_options.add_argument("--silent")
chrome_options.add_argument("--disable-extensions")
chrome_options.add_argument("--disable-plugins")
chrome_options.add_argument("--disable-web-security")
chrome_options.add_argument("--disable-features=VizDisplayCompositor")
chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
chrome_options.add_experimental_option('useAutomationExtension', False)

import logging
logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)

try:
    from webdriver_manager.chrome import ChromeDriverManager
    service = ChromeService(ChromeDriverManager().install())
    print("âœ… webdriver-managerë¡œ ChromeDriver ì„¤ì • ì™„ë£Œ")
except ImportError:
    service = ChromeService()
    print("âœ… ì‹œìŠ¤í…œ ChromeDriver ì‚¬ìš©")

driver = webdriver.Chrome(service=service, options=chrome_options)

def normalize_url(url):
    """URL ì •ê·œí™” (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì •ë ¬, ì¤‘ë³µ ì œê±°ìš©)"""
    if not url:
        return None
    if "?hl=ko" not in url and "&hl=ko" not in url:
        if "?" in url:
            url = url + "&hl=ko"
        else:
            url = url + "?hl=ko"
    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)
    normalized_query = "&".join(sorted([f"{k}={v[0]}" for k, v in query_params.items()]))
    return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{normalized_query}"

def expand_sidebar_sections(driver, wait):
    """ì‚¬ì´ë“œë°”ì˜ ì ‘íŒ ì„¹ì…˜ë“¤ì„ ëª¨ë‘ í¼ì¹˜ê¸°"""
    try:
        print("ğŸ”„ ì‚¬ì´ë“œë°” ì„¹ì…˜ í™•ì¥ ì¤‘...")
        expand_selectors = [
            'button[aria-expanded="false"]',
            '.devsite-nav-toggle',
            'button[aria-controls]',
            '[data-category="referencenav"]',
            '.devsite-nav-item-toggle',
            '.devsite-nav-expandable > button',
            '.devsite-nav-item.devsite-nav-expandable',
            '.devsite-nav-accordion button',
            '.devsite-nav-section button'
        ]
        expanded_count = 0
        max_attempts = 5
        for attempt in range(max_attempts):
            current_expanded = 0
            for selector in expand_selectors:
                try:
                    buttons = driver.find_elements(By.CSS_SELECTOR, selector)
                    for button in buttons:
                        try:
                            if button.is_displayed() and button.is_enabled():
                                aria_expanded = button.get_attribute('aria-expanded')
                                if aria_expanded == 'false':
                                    driver.execute_script("arguments[0].click();", button)
                                    current_expanded += 1
                                    time.sleep(0.2)
                        except Exception:
                            continue
                except Exception:
                    continue
            if current_expanded == 0:
                break
            expanded_count += current_expanded
            time.sleep(0.5)
        print(f"âœ… {expanded_count}ê°œ ì„¹ì…˜ í™•ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ì„¹ì…˜ í™•ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

def collect_all_tabs(driver):
    """í˜ì´ì§€ì˜ ëª¨ë“  íƒ­ ìˆ˜ì§‘"""
    tabs = []
    try:
        main_tab_selectors = [
            'nav[role="tablist"] a',
            '.devsite-tabs a',
            'devsite-tabs tab',
            '.devsite-nav-tabs a'
        ]
        for selector in main_tab_selectors:
            try:
                tab_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for tab in tab_elements:
                    href = tab.get_attribute('href')
                    text = (tab.text or '').strip()
                    if href and text and "developers.google.com/maps" in href:
                        tabs.append({
                            'name': text,
                            'url': normalize_url(href),
                            'element': tab
                        })
            except Exception:
                continue
        print(f"ğŸ¯ {len(tabs)}ê°œ íƒ­ ë°œê²¬")
        return tabs
    except Exception as e:
        print(f"âš ï¸ íƒ­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def collect_sidebar_links(driver, wait, current_tab_name="ê¸°ë³¸"):
    """í˜„ì¬ í˜ì´ì§€ì˜ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“  ë§í¬ ìˆ˜ì§‘"""
    try:
        print(f"ğŸ” [{current_tab_name}] ì‚¬ì´ë“œë°” ë§í¬ ìˆ˜ì§‘ ì¤‘...")
        expand_sidebar_sections(driver, wait)
        sidebar_selectors = [
            'devsite-book-nav',
            '.devsite-nav-list',
            '.devsite-section-nav',
            '[role="navigation"]',
            '.devsite-nav',
            'nav.devsite-nav',
            '.devsite-nav-accordion'
        ]
        nav_container = None
        for selector in sidebar_selectors:
            try:
                nav_container = driver.find_element(By.CSS_SELECTOR, selector)
                if nav_container:
                    print(f"âœ… [{current_tab_name}] ì‚¬ì´ë“œë°” ë°œê²¬: {selector}")
                    break
            except NoSuchElementException:
                continue
        if not nav_container:
            print(f"âš ï¸ [{current_tab_name}] ì‚¬ì´ë“œë°”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ í˜ì´ì§€ì—ì„œ ê²€ìƒ‰")
            nav_container = driver.find_element(By.TAG_NAME, "body")
        link_elements = nav_container.find_elements(By.TAG_NAME, "a")
        urls_to_crawl = []
        for elem in link_elements:
            href = elem.get_attribute("href")
            if href and "/maps/documentation/address-validation" in href and "developers.google.com" in href:
                normalized_url = normalize_url(href)
                if normalized_url and normalized_url not in visited_urls:
                    urls_to_crawl.append(normalized_url)
        unique_urls = list(dict.fromkeys(urls_to_crawl))
        print(f"âœ… [{current_tab_name}] {len(unique_urls)}ê°œì˜ ìƒˆë¡œìš´ ë§í¬ ìˆ˜ì§‘")
        return unique_urls
    except Exception as e:
        print(f"âŒ [{current_tab_name}] ì‚¬ì´ë“œë°” ë§í¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return []

def process_tabs_in_article(driver, article_element):
    """article ë‚´ì˜ íƒ­ ê·¸ë£¹ ì²˜ë¦¬"""
    try:
        tab_groups = article_element.find_elements(By.TAG_NAME, "devsite-selector")
        if not tab_groups:
            return article_element.text
        print(f"ğŸ¯ {len(tab_groups)}ê°œ íƒ­ ê·¸ë£¹ ë°œê²¬, ì²˜ë¦¬ ì¤‘...")
        final_page_text = article_element.text
        for tab_group_idx, tab_group in enumerate(tab_groups):
            tab_texts = []
            tab_buttons = tab_group.find_elements(
                By.CSS_SELECTOR, "devsite-tabs tab:not(.devsite-overflow-tab)"
            )
            if not tab_buttons:
                continue
            def get_tab_name(btn):
                txt = (btn.text or "").strip()
                if txt:
                    return txt
                return (
                    btn.get_attribute("aria-controls")
                    or btn.get_attribute("id")
                    or btn.get_attribute("data-tab")
                    or f"UNNAMED_TAB_{tab_group_idx}"
                )
            tab_panels = tab_group.find_elements(
                By.CSS_SELECTOR, "section[role='tabpanel']"
            )
            panels_by_key = {}
            for p in tab_panels:
                key = p.get_attribute("data-tab")
                if not key:
                    labelledby = p.get_attribute("aria-labelledby") or ""
                    if labelledby.startswith("aria-tab-"):
                        key = labelledby.replace("aria-tab-", "")
                if key:
                    panels_by_key[key] = p
            for btn_idx, btn in enumerate(tab_buttons):
                tab_key = (
                    btn.get_attribute("data-tab") 
                    or btn.get_attribute("id") 
                    or f"tab_{btn_idx}"
                )
                tab_name = get_tab_name(btn)
                panel_text = ""
                panel = panels_by_key.get(tab_key)
                if panel is None:
                    try:
                        driver.execute_script("arguments[0].click();", btn)
                        time.sleep(0.5)
                        panel = tab_group.find_element(
                            By.CSS_SELECTOR,
                            f"section[role='tabpanel'][data-tab='{tab_key}']",
                        )
                    except Exception:
                        panel = None
                if panel is not None:
                    try:
                        code_block = panel.find_element(
                            By.CSS_SELECTOR, "pre.devsite-code-highlight"
                        )
                        panel_text = code_block.get_attribute("textContent").strip()
                    except NoSuchElementException:
                        panel_text = (panel.get_attribute("textContent") or "").strip()
                else:
                    panel_text = "(íŒ¨ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)"
                tab_texts.append(f"--- íƒ­: {tab_name} ---\n{panel_text}")
            formatted_tab_content = "\n\n".join(tab_texts)
            if tab_group.text and formatted_tab_content:
                final_page_text = final_page_text.replace(
                    tab_group.text, formatted_tab_content, 1
                )
        return final_page_text
    except Exception as e:
        print(f"âš ï¸ íƒ­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return article_element.text

def add_links_to_text(driver, article_element):
    """article ë‚´ì˜ ëª¨ë“  ë§í¬ì— [URL] í˜•íƒœë¡œ ì£¼ì†Œ ì¶”ê°€"""
    try:
        links_in_article = article_element.find_elements(By.TAG_NAME, "a")
        link_count = 0
        for link in links_in_article:
            href = link.get_attribute("href")
            if href and "javascript:void(0)" not in href and href.startswith("http"):
                try:
                    driver.execute_script(
                        "arguments[0].textContent = arguments.textContent.trim() + ' [' + arguments.href + ']';",
                        link
                    )
                    link_count += 1
                except Exception:
                    continue
        if link_count > 0:
            print(f"ğŸ”— {link_count}ê°œ ë§í¬ì— URL ì£¼ì†Œ ì¶”ê°€ ì™„ë£Œ")
    except StaleElementReferenceException:
        print("âš ï¸ ë§í¬ ìˆ˜ì • ì¤‘ DOM ë³€ê²½ìœ¼ë¡œ ì¼ë¶€ ë§í¬ ì²˜ë¦¬ ë¶ˆê°€")
    except Exception as e:
        print(f"âš ï¸ ë§í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

def crawl_page(url, tab_name="ê¸°ë³¸"):
    """ê°œë³„ í˜ì´ì§€ í¬ë¡¤ë§"""
    try:
        print(f"ğŸ“„ [{tab_name}] í¬ë¡¤ë§ ì¤‘: {url}")
        driver.get(url)
        wait = WebDriverWait(driver, 15)
        try:
            wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            time.sleep(2)
        except TimeoutException:
            print(f"âš ï¸ [{tab_name}] í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
            return False
        try:
            article_element = wait.until(
                EC.presence_of_element_located((By.TAG_NAME, "article"))
            )
        except TimeoutException:
            try:
                article_element = wait.until(
                    EC.presence_of_element_located((By.TAG_NAME, "main"))
                )
            except TimeoutException:
                article_element = driver.find_element(By.TAG_NAME, "body")
        add_links_to_text(driver, article_element)
        final_page_text = process_tabs_in_article(driver, article_element)
        path = url.split("?")[0].replace(BASE_URL, "")
        safe_tab_name = re.sub(r'[/\\?%*:|"<>]', "_", tab_name)
        filename = f"{safe_tab_name}_{re.sub(r'[/\\?%*:|\\"<>]', '_', path).strip('_')}.txt"
        filepath = os.path.join(OUTPUT_DIR, filename)
        content_to_save = f"Tab: {tab_name}\nSource URL: {url}\n\n{final_page_text}"
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content_to_save)
        file_size = len(content_to_save)
        print(f"âœ… [{tab_name}] ì €ì¥ ì™„ë£Œ: {filename} ({file_size:,} ê¸€ì)")
        visited_urls.add(url)
        return True
    except Exception as e:
        print(f"âŒ [{tab_name}] í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {url} - {e}")
        return False

try:
    full_start_url = urljoin(BASE_URL, START_URL)
    print(f"ğŸš€ ì‹œì‘ í˜ì´ì§€ë¡œ ì´ë™: {full_start_url}")
    driver.get(full_start_url)
    wait = WebDriverWait(driver, 15)
    try:
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(3)
        print("âœ… í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
    except TimeoutException:
        print("âš ï¸ í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰...")

    main_tabs = collect_all_tabs(driver)
    all_urls_to_crawl = []
    print("\nğŸ“‹ ê¸°ë³¸ í˜ì´ì§€ì—ì„œ ë§í¬ ìˆ˜ì§‘...")
    base_urls = collect_sidebar_links(driver, wait, "ê¸°ë³¸")
    for url in base_urls:
        all_urls_to_crawl.append(("ê¸°ë³¸", url))

    for tab in main_tabs:
        tab_name = tab['name']
        tab_url = tab['url']
        if tab_url in visited_urls:
            continue
        try:
            print(f"\nğŸ¯ [{tab_name}] íƒ­ìœ¼ë¡œ ì´ë™: {tab_url}")
            driver.get(tab_url)
            time.sleep(2)
            tab_urls = collect_sidebar_links(driver, wait, tab_name)
            for url in tab_urls:
                all_urls_to_crawl.append((tab_name, url))
        except Exception as e:
            print(f"âŒ [{tab_name}] íƒ­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    all_urls_to_crawl.insert(0, ("ê¸°ë³¸", normalize_url(full_start_url)))
    seen_urls = set()
    unique_urls_to_crawl = []
    for tab_name, url in all_urls_to_crawl:
        if url not in seen_urls:
            seen_urls.add(url)
            unique_urls_to_crawl.append((tab_name, url))

    print(f"\nğŸ¯ ì´ {len(unique_urls_to_crawl)}ê°œ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘")
    print("=" * 70)

    successful_count = 0
    failed_count = 0

    for i, (tab_name, url) in enumerate(unique_urls_to_crawl):
        print(f"\n({i+1}/{len(unique_urls_to_crawl)})")
        if crawl_page(url, tab_name):
            successful_count += 1
        else:
            failed_count += 1
        time.sleep(1.5)

    print("\n" + "=" * 70)
    print("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
    print("=" * 70)
    print(f"âœ… ì„±ê³µ: {successful_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"ğŸ“ ì €ì¥ í´ë”: {OUTPUT_DIR}")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬: {len(unique_urls_to_crawl)}ê°œ")
    print("=" * 70)

except Exception as e:
    print(f"ğŸ’¥ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")

finally:
    try:
        if 'driver' in locals():
            driver.quit()
    except Exception as e:
        print(f"âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
    print("\nğŸ”š ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
